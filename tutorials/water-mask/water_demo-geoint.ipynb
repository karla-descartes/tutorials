{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping waterlogged areas over the monsoon season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The monsoon season brings the majority of the annual rainfall to the wet tropical regions of Asia. In a normal year in  Bangladesh, nearly 20% of the country will be underwater after heavy rains and snowmelt cause coastal regions, rivers, and other areas to flood during the June to October monsoon season. \n",
    "\n",
    "To examine the changes in water occurance over the region, we'll use both multispectral and Synthetic Aperture Radar (SAR) data available through the DL Platform. Our goal is to produce a monthly snapshot of water coverage. Using a simple classification method to identify water, we'll produce a water product and upload it to our Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import descarteslabs as dl\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "# import cartopy\n",
    "# import shapely\n",
    "# import shapely.geometry\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import calendar\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "import sklearn.ensemble\n",
    "# from descarteslabs.client.services.catalog import catalog\n",
    "\n",
    "# product_id = '6298b97d846a85f9045e8173d1f052c571b48cae:demo:water:bangladesh:v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by prototyping and examining the data over a smaller region before scaling it to the entire country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = {\n",
    "  \"type\": \"Feature\",\n",
    "  \"properties\": {},\n",
    "  \"geometry\": {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "      [\n",
    "        [\n",
    "          103.5791015625,\n",
    "          1.1342642839220822\n",
    "        ],\n",
    "        [\n",
    "          104.13940429687499,\n",
    "          1.1342642839220822\n",
    "        ],\n",
    "        [\n",
    "          104.13940429687499,\n",
    "          1.4884800029826135\n",
    "        ],\n",
    "        [\n",
    "          103.5791015625,\n",
    "          1.4884800029826135\n",
    "        ],\n",
    "        [\n",
    "          103.5791015625,\n",
    "          1.1342642839220822\n",
    "        ]\n",
    "      ]\n",
    "    ]\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In selecting classification features to identify water, we will state several assumptions about the spectral response of water relative to other land cover types:\n",
    "\n",
    "* We expect backscatter over standing water and submerged areas from SAR to be very low in all polarizations.\n",
    "* We expect NDVI to be low relative to vegetated areas.\n",
    "* We expect NDWI to be high relative to unsubmerged areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = 1.33883688455388, 103.8369369506836\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile = dl.raster.dltile_from_latlon(lat, \n",
    "                                    lon, \n",
    "                                    resolution = 20.0,\n",
    "                                    tilesize = 1024,\n",
    "                                    pad = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available_scenes = dl.metadata.search(products=['sentinel-2:L1C'],\n",
    "#                                       dltile=tile,\n",
    "#                                       start_time='2017-01-01',\n",
    "#                                       end_time='2017-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_scenes, sent_2_ctx = dl.scenes.search(tile['geometry'],\n",
    "                               products=['sentinel-2:L1C'],\n",
    "                               start_datetime='2017-01-01',\n",
    "                               end_datetime='2017-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of scenes over ROI:         49\n"
     ]
    }
   ],
   "source": [
    "print('Total number of scenes over ROI: {:>10}'.format(len(available_scenes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop classification model - Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define classification features to calculate from the imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dic = {'sentinel-1:GRD': {'bands': ['vv', 'vh'], 'stats': 'min'},\n",
    "              'sentinel-2:L1C': {'bands': ['ndvi', 'ndwi', 'cloud-mask'], 'stats': 'max'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate and visualize a sample of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentinel-1:GRD\n",
      "3\n",
      "(masked_array(data=[2, 3, 4, ..., --, 255, --],\n",
      "             mask=[False, False, False, ...,  True, False,  True],\n",
      "       fill_value=999999,\n",
      "            dtype=uint8), array([  2,  64, 452, ...,   2, 212,   1]))\n",
      "[[-- 43 36 ... 100 73 --]\n",
      " [-- 27 38 ... 61 49 --]\n",
      " [-- 26 26 ... 60 123 --]\n",
      " ...\n",
      " [-- 79 50 ... 75 70 --]\n",
      " [-- 27 33 ... 255 255 --]\n",
      " [-- 22 32 ... 255 247 --]]\n",
      "(masked_array(data=[--],\n",
      "             mask=[ True],\n",
      "       fill_value=999999,\n",
      "            dtype=uint8), array([1050624]))\n",
      "[[-- -- -- ... -- -- --]\n",
      " [-- -- -- ... -- -- --]\n",
      " [-- -- -- ... -- -- --]\n",
      " ...\n",
      " [-- -- -- ... -- -- --]\n",
      " [-- -- -- ... -- -- --]\n",
      " [-- -- -- ... -- -- --]]\n",
      "(masked_array(data=[2, 3, 4, ..., --, 255, --],\n",
      "             mask=[False, False, False, ...,  True, False,  True],\n",
      "       fill_value=999999,\n",
      "            dtype=uint8), array([  2,  39, 350, ...,   2,  49,   1]))\n",
      "[[-- 65 83 ... 71 54 --]\n",
      " [-- 30 30 ... 59 36 --]\n",
      " [-- 70 109 ... 40 126 --]\n",
      " ...\n",
      " [-- 92 91 ... 58 60 --]\n",
      " [-- 57 34 ... 255 194 --]\n",
      " [-- 63 65 ... 255 166 --]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Band 'ndvi' is not available in the product 'sentinel-1:GRD'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4a3f0ef05370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mscene\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mavailable_scenes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ndvi ndwi cloud-mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#             print(scene.ndarray(bands=\"derived:ndvi ndwi cloud-mask\", ctx=ctx))else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/karlaking/miniconda2/envs/dl-docs/lib/python2.7/site-packages/descarteslabs/scenes/scene.pyc\u001b[0m in \u001b[0;36mndarray\u001b[0;34m(self, bands, ctx, mask_nodata, mask_alpha, bands_axis, raster_info, raster_client)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mbands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bands_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mcommon_data_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_common_data_type_of_bands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mself_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bands\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/karlaking/miniconda2/envs/dl-docs/lib/python2.7/site-packages/descarteslabs/scenes/scene.pyc\u001b[0m in \u001b[0;36m_common_data_type_of_bands\u001b[0;34m(self, bands)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 six.raise_from(\n\u001b[1;32m    416\u001b[0m                     \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Band '{}' is not available in the product '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"product\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m                     \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m                 )\n\u001b[1;32m    419\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/karlaking/miniconda2/envs/dl-docs/lib/python2.7/site-packages/six.pyc\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Band 'ndvi' is not available in the product 'sentinel-1:GRD'"
     ]
    }
   ],
   "source": [
    "date = ['2017-01-01', '2017-01-31']\n",
    "\n",
    "all_stats = []   \n",
    "for product in sorted(product_dic.keys()):\n",
    "    print(product)\n",
    "    ''' DL Metadata search for imagery over our AOI'''\n",
    "#     available_scenes = dl.metadata.search(products = [product],\n",
    "#                                           dltile = tile,\n",
    "#                                           start_time = date[0],\n",
    "#                                           end_time = date[1])\n",
    "    available_scenes, ctx = dl.scenes.search(tile['geometry'],\n",
    "                               products=[product],\n",
    "                               start_datetime=date[0],\n",
    "                               end_datetime=date[1])\n",
    "\n",
    "#     ids = [scene['id'] for scene in available_scenes['features']]\n",
    "    \n",
    "    bands = product_dic[product]['bands']\n",
    "    \n",
    "    image_stack = None\n",
    "    print(len(available_scenes))\n",
    "    if product == 'sentinel-1:GRD':\n",
    "        for scene in available_scenes:\n",
    "            image, meta = scene.ndarray(\"vv vh\", ctx=ctx, mask_alpha=False)\n",
    "            print(np.unique(meta, return_counts=True))\n",
    "            print(meta)\n",
    "                  \n",
    "    \n",
    "        for scene in available_scenes:\n",
    "            print(scene.ndarray(\"ndvi ndwi cloud-mask\", ctx=ctx))\n",
    "#             print(scene.ndarray(bands=\"derived:ndvi ndwi cloud-mask\", ctx=ctx))else: \n",
    "            \n",
    "\n",
    "#     for i, idd in enumerate(ids):\n",
    "\n",
    "#         ''' DL Raster search to obtain image data '''\n",
    "        \n",
    "#         image, meta = dl.raster.ndarray(idd,\n",
    "#                                         bands = bands,\n",
    "#                                         dltile = tile)\n",
    "    \n",
    "\n",
    "#         if image_stack is None:\n",
    "\n",
    "#             rx = image.shape[0]\n",
    "#             ry = image.shape[1]\n",
    "#             n_images = len(ids)\n",
    "#             n_bands = 2\n",
    "#             image_stack = np.zeros((n_images, rx, ry, n_bands))\n",
    "\n",
    "#         ''' Mask the clouds '''\n",
    "#         if \"cloud-mask\" in bands:\n",
    "#             cloud_mask = image[:, :, 2]\n",
    "#             image[cloud_mask == 1] = 0\n",
    "#             image_stack[i, :, :, :] = image[:, :, :2]\n",
    "            \n",
    "#         else:\n",
    "#             image_stack[i, :, :, :] = image\n",
    "\n",
    "    \n",
    "#     if product_dic[product]['stats'] == 'min':\n",
    "#         ma = np.ma.masked_equal(image_stack, 0, copy = False)\n",
    "#         all_stats.append(np.ma.min(ma, axis=0))\n",
    "        \n",
    "#     else:\n",
    "#         all_stats.append(np.max(image_stack, axis = 0)[:, :, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `dl.raster.ndarray` parameters, we can resample and align disparate datasets to the same resolution, projection, and grid alignment. Each of the resulting arrays thus have the same shape and size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sentinel-1 data shape: {}'.format(all_stats[0].shape))\n",
    "print('Sentinel-2 data shape: {}'.format(all_stats[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the stats into a single array\n",
    "all_stats = np.dstack(all_stats).data\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "labels = ['Sentinel-1 Min VV', \n",
    "         'Sentinel-1 Min VH', \n",
    "         'Sentinel-2 Max NDVI',\n",
    "         'Sentinel-2 Max NDWI']\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    ax = plt.subplot(2, 2, i + 1)\n",
    "    ax.imshow(all_stats[:, :, i])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(labels[i])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a simple decision rule based on image threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.where(((all_stats[:, :, 0] < 60) & (all_stats[:, :, 1] < 60)\n",
    "         & (all_stats[:, :, 2] < 35000) & (all_stats[:, :, 3] > 35000)), 1, 0)\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.imshow(mask, cmap='Blues')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a simple, supervised machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different ways obtain training data using the Descartes Labs Platform:\n",
    "1. Load existing reference information and extract image data\n",
    "2. Use an existing Platform product (e.g. Cropland Data Layer) to sample reference data\n",
    "3. Digitize reference data using Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('water_train.json') as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = [[feature['properties']['vv'],\n",
    "                  feature['properties']['vh'],\n",
    "                  feature['properties']['ndvi'],\n",
    "                  feature['properties']['ndwi']] for feature in train_data['features']]\n",
    "\n",
    "labels = [feature['properties']['class'] for feature in train_data['features']]\n",
    "\n",
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier(n_estimators=10, \n",
    "                                              criterion='gini', \n",
    "                                              min_samples_split=2, \n",
    "                                              min_samples_leaf=1, \n",
    "                                              min_weight_fraction_leaf=0.0, \n",
    "                                              max_features='auto', \n",
    "                                              bootstrap=True, \n",
    "                                              n_jobs=1)\n",
    "\n",
    "clf.fit(train_features, labels)\n",
    "\n",
    "print('feature importances\\n')\n",
    "for fi, label in zip(clf.feature_importances_, ['vv', 'vh', 'ndvi', 'ndwi']): \n",
    "    print(\"{:<10}: {:5f}\".format(label, fi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the classifier to storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from descarteslabs.ext.storage import Storage\n",
    "storage_client = Storage()\n",
    "\n",
    "classifier_key = 'water_demo_classifier'\n",
    "storage_client.set(classifier_key, pickle.dumps(clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = all_stats.reshape(all_stats.shape[0]*all_stats.shape[1], all_stats.shape[2])\n",
    "predictions = clf.predict(features)\n",
    "predictions = predictions.reshape(all_stats.shape[0], all_stats.shape[1])\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.imshow(predictions, cmap='Blues')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now create a tiling over Bangladesh to efficiently scale the process.\n",
    "\n",
    "Here, we will be getting imagery over Bangladesh, calculating the image features for the classification, using the clustering algorithm to identify water in the image, and saving the resulting water mask to a new product cataloged in the Descartes Labs Platform.\n",
    "\n",
    "First, we'll create a new product for the water mask results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DL Catalog to create a new product '''\n",
    "from descarteslabs.ext.catalog import catalog\n",
    "\n",
    "\n",
    "product_id = catalog.add_product('demo:water:bangladesh:v1',\n",
    "                                  title='Water mask',\n",
    "                                  description='Water mask derived from Sentinel-1 and -2 for demo'\n",
    "                                  )['data']['id']\n",
    "\n",
    "colormap = [['255', '255', '255', '255'],\n",
    "            ['66', '134', '244', '255']]\n",
    "\n",
    "band_id = catalog.add_band(product_id,  \n",
    "                           'water',\n",
    "                           jpx_layer=0,\n",
    "                           srcfile=0,\n",
    "                           srcband=1,  \n",
    "                           nbits=8,\n",
    "                           dtype='Byte',\n",
    "                           nodata=255,\n",
    "                           data_range=[0, 2**8 - 1],\n",
    "                           type='class',\n",
    "                           default_range=(0,255),\n",
    "                           colormap=colormap)['data']['id']\n",
    "print product_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define dates of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2017'\n",
    "\n",
    "dates = []\n",
    "for month in range(3,11,2):\n",
    "    str_month = str(month).zfill(2)\n",
    "    last_day = calendar.monthrange(int(year), month)[1]\n",
    "    dates.append(['{}-{}-{}'.format(year, str_month, '01'), '{}-{}-{}'.format(year,str_month,last_day)])\n",
    "\n",
    "pprint([\"{} - {}\".format(date[0], date[1]) for date in dates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next, we create a tiling over Bangladesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DLTiles to create a global tiling across our AOI '''\n",
    "\n",
    "resolution = 20\n",
    "tile_dimension = 2048\n",
    "pad = 20\n",
    "\n",
    "tiles = dl.raster.dltiles_from_shape(resolution = resolution, \n",
    "                                     tilesize = tile_dimension, \n",
    "                                     pad = pad, \n",
    "                                     shape = country)\n",
    "\n",
    "print('Number of tiles = {}'.format(len(tiles['features'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, we write our function to do the classification and save the product to file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_task(tile, dates, product_dic, clf_key, product_id):\n",
    "    \"\"\" predict water over dltile with Tasks \"\"\"\n",
    "    \n",
    "    import descarteslabs as dl\n",
    "    from descarteslabs.ext.catalog import Catalog\n",
    "    from descarteslabs.ext.storage import Storage\n",
    "    \n",
    "    storage_client = Storage()\n",
    "    catalog = Catalog()\n",
    "    \n",
    "    import os\n",
    "    from osgeo import gdal, osr, ogr\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import sklearn\n",
    "    import sklearn.ensemble\n",
    "    \n",
    "    def geotransform_from_dltile(dltile):\n",
    "        \"\"\"Returns the geotransform from a given dltile\n",
    "        Inputs:\n",
    "            DLTILE (dict) - dltile as returned by dl.raster.dltile()\n",
    "        Returns:\n",
    "            GEOTRANSFORM (tuple) - six parameter georeferencing transform as used by GDAL\n",
    "        \"\"\"\n",
    "\n",
    "        geotransform = (dltile['properties']['outputBounds'][0], dltile['properties']['resolution'], 0,\n",
    "                        dltile['properties']['outputBounds'][3], 0, -dltile['properties']['resolution'])\n",
    "\n",
    "        return geotransform\n",
    "\n",
    "    def prj_from_dltile(dltile):\n",
    "        \"\"\"Returns projection as WKT from dltile\n",
    "        Inputs:\n",
    "            DLTILE (dict) - dltile as returned by dl.raster.dltile()\n",
    "        \"\"\"\n",
    "\n",
    "        prj = osr.SpatialReference()\n",
    "        prj.ImportFromEPSG(int(dltile['properties']['cs_code'].split(':')[1]))\n",
    "\n",
    "        return prj.ExportToWkt()\n",
    "\n",
    "    def save_ds(arr, tile, outfile):\n",
    "            \"\"\" save numpy array to tiff using dltile meta \"\"\"\n",
    "\n",
    "            geotransform = geotransform_from_dltile(tile)\n",
    "            prj = prj_from_dltile(tile)\n",
    "\n",
    "            driver = gdal.GetDriverByName('GTiff')\n",
    "            opts = ['TILED=YES', 'COMPRESS=LZW']\n",
    "            out_ds  = driver.Create(outfile, arr.shape[1], arr.shape[0], 1, gdal.GDT_Byte, options=opts)\n",
    "            out_ds.SetGeoTransform(geotransform)\n",
    "            out_ds.SetProjection(prj)\n",
    "\n",
    "            out_band = out_ds.GetRasterBand(1)\n",
    "            out_band.WriteArray(arr)\n",
    "\n",
    "            out_ds = None\n",
    "            arr = None\n",
    "\n",
    "    def search_and_raster(product, product_dic, tile, date):\n",
    "\n",
    "        # metadata search for available imagery\n",
    "        available_scenes = dl.metadata.search(products=[product],\n",
    "                                               geom=tile['geometry'],\n",
    "                                               start_time=date[0],\n",
    "                                               end_time=date[1])\n",
    "\n",
    "        # scene ids and bands\n",
    "        ids = [scene['id'] for scene in available_scenes['features']]\n",
    "        bands = product_dic[product]['bands']\n",
    "\n",
    "        # get each image as ndarray\n",
    "        image_stack = None\n",
    "        for i, idd in enumerate(ids):\n",
    "\n",
    "            image, meta = dl.raster.ndarray(idd,\n",
    "                                           bands = bands,\n",
    "                                           dltile = tile,\n",
    "                                           resampler='near')\n",
    "\n",
    "            # initialize empty array to hold each image\n",
    "            if image_stack is None:\n",
    "\n",
    "                rx = image.shape[0]\n",
    "                ry = image.shape[1]\n",
    "                n_images = len(ids)\n",
    "                n_bands = 2\n",
    "                image_stack = np.zeros((n_images, rx, ry, n_bands))\n",
    "\n",
    "            # mask clouds if applicable\n",
    "            image_stack[i, :, :, :] = cloud_mask(image, bands)\n",
    "\n",
    "        return image_stack\n",
    "\n",
    "    def cloud_mask(image, bands):\n",
    "        ''' apply cloud-mask if requested in bands list '''\n",
    "\n",
    "        if 'cloud-mask' in bands:\n",
    "            cloud_mask = image[:, :, 2]\n",
    "            image[cloud_mask == 1] = 0\n",
    "\n",
    "            return image[:, :, :2]\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def calc_stat(image_stack, stat):\n",
    "        ''' calculate stat over time dimension'''\n",
    "\n",
    "        if stat == 'min':\n",
    "            ma = np.ma.masked_equal(image_stack, 0, copy=False)\n",
    "            return np.ma.min(ma, axis=0).data\n",
    "        else:\n",
    "            return np.max(image_stack, axis=0)[:,:,:2]\n",
    "    \n",
    "    \n",
    "    ''' predict water over each compositing period '''\n",
    "    outdir = os.path.join(os.path.expanduser('~'), 'temp')\n",
    "    if not os.path.isdir(outdir):\n",
    "            os.makedirs(outdir)\n",
    "\n",
    "    clf = pickle.loads(storage_client.get(clf_key))\n",
    "    key = tile['properties']['key']\n",
    "    \n",
    "    for date in dates:\n",
    "\n",
    "        outfile = '{}/water_{}_{}_{}.tif'.format(outdir, key, date[0], date[1])\n",
    "        \n",
    "        # get imagery and stats for each product\n",
    "        all_stats = []\n",
    "        for product in sorted(product_dic.keys()):\n",
    "\n",
    "            image_stack = search_and_raster(product, product_dic, tile, date)\n",
    "            stats = calc_stat(image_stack, product_dic[product]['stats'])\n",
    "            all_stats.append(stats)\n",
    "\n",
    "        # combine the stats into a single array\n",
    "        all_stats = np.dstack(all_stats).astype(int)\n",
    "        rx = all_stats.shape[0]\n",
    "        ry = all_stats.shape[1]\n",
    "        n_features = all_stats.shape[2]\n",
    "\n",
    "        # predict and reshape\n",
    "        predictions = clf.predict(all_stats.reshape(rx*ry, n_features))\n",
    "        predictions = predictions.reshape(rx, ry)\n",
    "\n",
    "        # save to product to Catalog\n",
    "        save_ds(predictions, tile, outfile)\n",
    "        catalog.upload_image(outfile, product_id, acquired=date[0])\n",
    "        \n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DL Tasks to run the job '''\n",
    "\n",
    "from descarteslabs.client.services.tasks import AsyncTasks, as_completed\n",
    "at = AsyncTasks()\n",
    "\n",
    "async_function = at.create_function(predict_task, \n",
    "                                    name=\"demo-predict-water\",\n",
    "                                    memory='5Gi',\n",
    "                                    image='us.gcr.io/dl-ci-cd/images/tasks/public/alpha/py2/default:v2018.04.26',\n",
    "                                    task_timeout=1000\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Submit DL Tasks '''\n",
    "\n",
    "tasks = [async_function(tile, dates, product_dic, classifier_key, product_id) for tile in tiles['features']]\n",
    "\n",
    "for task in as_completed(tasks):\n",
    "    key = task.result\n",
    "    print('Tile {} completed.'.format(key))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-docs",
   "language": "python",
   "name": "dl-docs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
